# -*- coding: utf-8 -*-
"""Project MARREL-VASSEUR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1L_FQ5oBJXVa-Q2n3hqrIkDn_87EKbqGb
"""

!pip install --upgrade pandas.profiling

!pip install mlforecast

import pandas as pd
from pandas_profiling import ProfileReport

"""### Visualization"""

traffic_df = pd.read_parquet('traffic_10lines.parquet')

traffic_df.info()

traffic_df.transpose()

profile_report = ProfileReport(traffic_df)

profile_report.to_notebook_iframe()

(traffic_df
 .groupby(['home_airport', 'paired_airport', 'direction'])
 .agg(date_min = ('date', 'min'), date_max = ('date', 'max'), pax = ('pax', 'sum'))
 .reset_index()
);

traffic_df.query('home_airport == "NTE" and paired_airport == "FUE"')['airline_name'].value_counts()

traffic_df.query('home_airport == "NTE" and paired_airport == "FUE" and pax > 100')['airline_name'].value_counts()

(traffic_df
 .query('home_airport == "NTE" and paired_airport == "FUE"')
 .groupby(['home_airport', 'paired_airport', 'date'])
 .agg(pax_total = ('pax', 'sum'))
 .reset_index()
 .set_index('date')['pax_total']
 .plot(figsize = (12,6))
);

(traffic_df
 .query('home_airport == "LGW" and paired_airport == "AMS"')
 .groupby(['home_airport', 'paired_airport', 'date'])
 .agg(pax_total = ('pax', 'sum'))
 .reset_index()
 .set_index('date')['pax_total']
 .plot(figsize = (12,6))
);

import seaborn as sns
sns.set()

(traffic_df
 .query('home_airport == "LGW" and paired_airport == "AMS"')
 .groupby(['home_airport', 'paired_airport', 'date'])
 .agg(pax_total = ('pax', 'sum'))
 .reset_index()
 .set_index('date')['pax_total']
 .plot(figsize = (12,6))
);

import datetime
import plotly
import pandas as pd

import plotly.offline as pyoff
import plotly.graph_objs as go

from plotly.subplots import make_subplots

def draw_ts_multiple(df: pd.DataFrame, v1: str, v2: str=None, prediction: str=None, date: str='date',
              secondary_y=True, covid_zone=False, display=True):
  """Draw times series possibly on two y axis, with COVID period option.
​
  Args:
  - df (pd.DataFrame): time series dataframe (one line per date, series in columns)
  - v1 (str | list[str]): name or list of names of the series to plot on the first x axis
  - v2 (str): name of the serie to plot on the second y axis (default: None)
  - prediction (str): name of v1 hat (prediction) displayed with a dotted line (default: None)
  - date (str): name of date column for time (default: 'date')
  - secondary_y (bool): use a secondary y axis if v2 is used (default: True)
  - covid_zone (bool): highlight COVID-19 period with a grayed rectangle (default: False)
  - display (bool): display figure otherwise just return the figure (default: True)
​
  Returns:
  - fig (plotly.graph_objs._figure.Figure): Plotly figure generated
​
  Notes:
  Make sure to use the semi-colon trick if you don't want to have the figure displayed twice.
  Or use `display=False`.
  """
  if isinstance(v1, str):
    variables = [(v1, 'V1')]
  else:
    variables = [(v, 'V1.{}'.format(i)) for i, v in enumerate(v1)]
  title = ''.join([n + ': '+ v for v, n in variables]) + ('V2: ' + v2) if v2 else ''.join([v + ': '+ n for v, n in variables])
  layout = dict(
    title=title,
    xaxis=dict(
        rangeselector=dict(
            buttons=list([
                dict(count=1,
                     label='1m',
                     step='month',
                     stepmode='backward'),
                dict(count=6,
                     label='6m',
                     step='month',
                     stepmode='backward'),
                dict(step='all')
            ])
        ),
        rangeslider=dict(
            visible = True
        ),
        type='date'
    )
  )
  fig = make_subplots(specs=[[{"secondary_y": True}]])
  fig.update_layout(layout)
  for v, name in variables:
    fig.add_trace(go.Scatter(x=df[date], y=df[v], name=name), secondary_y=False)
  if v2:
    fig.add_trace(go.Scatter(x=df[date], y=df[v2], name='V2'), secondary_y=secondary_y)
    fig['layout']['yaxis2']['showgrid'] = False
    fig.update_yaxes(rangemode='tozero')
    fig.update_layout(margin=dict(t=125 + 30 * (len(variables) - 1)))
  if prediction:
    fig.add_trace(go.Scatter(x=df[date], y=df[prediction], name='^V1', line={'dash': 'dot'}), secondary_y=False)

  if covid_zone:
    fig.add_vrect(
        x0=pd.Timestamp("2020-03-01"), x1=pd.Timestamp("2022-01-01"),
        fillcolor="Gray", opacity=0.5,
        layer="below", line_width=0,
    )
  if display:
    pyoff.iplot(fig)
  return fig

draw_ts_multiple(
    (traffic_df
     .query('home_airport == "LGW" and paired_airport == "AMS"')
     .groupby(['home_airport', 'paired_airport', 'date'])
     .agg(pax_total=('pax', 'sum'))
     .reset_index()
    ),
    'pax_total' 
)

draw_ts_multiple(
    (traffic_df
     .query('home_airport == "LGW" and paired_airport == "AMS"')
     .groupby(['home_airport', 'paired_airport', 'date'])
     .agg(pax_total=('pax', 'sum'))
     .reset_index()
    ),
    'pax_total',
    covid_zone = True,
)

nte_fue_df = (traffic_df
 .query('home_airport == "NTE" and paired_airport == "FUE"')
 .groupby(['home_airport', 'paired_airport', 'date'])
 .agg(pax_total = ('pax', 'sum'))
 .reset_index()
)
nte_fue_df

lgw_ams_df = (traffic_df
 .query('home_airport == "LGW" and paired_airport == "AMS"')
 .groupby(['home_airport', 'paired_airport', 'date'])
 .agg(pax_total = ('pax', 'sum'))
 .reset_index()
)
lgw_ams_df

"""### First model with facebook prophete"""

traffic_df

def generate_route_df(traffic_df : pd.DataFrame, homeAirport: str, pairedAirport: str) -> pd.DataFrame:
  """Extract route dataframe from traffic dataframe for route from home airport to paired airport

  Args:
  - traffic_pd (pd.DataFrame): traffic dataframe
  - homeAirport (str): IATA Code for home airport
  - pairedAirport (str): IATA Code for paired airport

  Returns:
  - pd.DataFrame: daily traffic on route (home-paired)
  """
  _df = (traffic_df
         .query('home_airport == "{home}" and paired_airport == "{paired}"'.format(home = homeAirport, paired = pairedAirport))
         .groupby(['home_airport', 'paired_airport', 'date'])
         .agg(pax_total = ('pax', 'sum'))
         .reset_index()
         )
  return _df

generate_route_df(traffic_df, "LGW", "AMS")

from prophet import Prophet

baseline_model = Prophet()
baseline_model.fit(generate_route_df(traffic_df,"NTE", "FUE").rename(columns ={'date': 'ds', 'pax_total':'y'}))

future_df = baseline_model.make_future_dataframe(periods=15) #prepare to predict 15 days
future_df

forecast_df = baseline_model.predict(future_df)
forecast_df

fig_1 = baseline_model.plot(forecast_df)

fig_2 = baseline_model.plot_components(forecast_df)

"""### Evaluate performance"""

from prophet.diagnostics import cross_validation

#5 fold de 3 mois

eval_df = cross_validation(baseline_model, initial = '366 days', period = '90 days', horizon = '90 days')

eval_df
#1er cut : jusqu'a 16 sept 2020 => prévision 30 jours plus tard : 18 oct prévision est de 447
#Il s'arrete a la cutoff date et predict (yhat) a la date ds
#Il c'est arréter le 5 decembre 2022 et il a prédit pour le 5 mars 2023, prédit 555 alors que la vrai valeure est 290 => pb lié au c

from prophet.diagnostics import performance_metrics

performance_metrics(eval_df)

from prophet.plot import plot_cross_validation_metric

plot_cross_validation_metric(eval_df, metric = 'rmse');

"""### Automate model fitting and evaluation"""

routes = (traffic_df
 .drop_duplicates(subset = ['home_airport', 'paired_airport'])
 [['home_airport', 'paired_airport']]
 .to_dict(orient = 'rows')
)

routes

#Permet de supprimer les DEBUG dans le code suivant => n'affiche que les messages de niveau WARNING
import logging 
logging.getLogger('cmdstanpy').setLevel(logging.WARNING)

models = dict()
performances = dict()

#models = {}
#performances = {}

for route in routes:
  print(route)
  home = route['home_airport']
  paired = route['paired_airport']

  #Build route traffic dataframe
  _df = generate_route_df(traffic_df, home, paired)

  #create a model 
  _model = Prophet()

  #Fit & evaluate the model
  _model.fit(_df.rename(columns ={'date': 'ds', 'pax_total':'y'}))

  #Cross validate the model
  ##parallel : permet de calculer plusieurs modeles en même temps
  _cv_df = cross_validation(_model, horizon = '90 days', parallel = "processes")
  ## rolling_window = 1 dit au model de sélectionner toutes les données, de base il n'en sélectionne que 10%
  _perf_df = performance_metrics(_cv_df, rolling_window = 1)

  #Save the model to a dictionnary
  models[(route['home_airport'], route['paired_airport'])] = _model
  performances[(route['home_airport'], route['paired_airport'])] = _perf_df['rmse'].values[0]

models

performances

"""### Save models"""

from prophet.serialize import model_to_json, model_from_json
#model[0] et model[1] renvoie LGW et BCN... du dict models

for model in models:
  _filename ='route_model_prophet_{home}_{paired}.json'.format(home = model[0], paired = model[1])
  #Save the file
  #w pour dire que l'on veut extraire le json
  with open(_filename, 'w') as f:
    f.write(model_to_json(models[model]))

reload_models = dict()

for route in routes:
  _filename ='route_model_prophet_{home}_{paired}.json'.format(home = route['home_airport'],
                                                               paired = route['paired_airport'])
  # r pour indiquer que je veux lire le fichier
  with open(_filename, 'r') as f:
    reload_models[(route['home_airport'], route['paired_airport'])] = model_from_json(f.read())

reload_models #avec json

from joblib import dump, load

from prophet.serialize import model_to_json, model_from_json

for model in models:
  _filename ='route_model_prophet_{home}_{paired}.joblib'.format(home = model[0], paired = model[1])
  dump(models[model], _filename)

reload_models = dict()

for route in routes:
  _filename ='route_model_prophet_{home}_{paired}.joblib'.format(home = route['home_airport'],
                                                               paired = route['paired_airport'])
  reload_models[(route['home_airport'], route['paired_airport'])] = load(_filename)

reload_models #avec joblib

"""### Model with Nixtla"""

import lightgbm as lgb
import xgboost as xgb
from sklearn.ensemble import RandomForestRegressor

models = [
    lgb.LGBMRegressor(),
    xgb.XGBRegressor(),
    RandomForestRegressor(random_state=0),
]

"""### ML Model"""

import lightgbm as lgb
import xgboost as xgb

from sklearn.ensemble import RandomForestRegressor
from mlforecast import MLForecast

from numba import njit
from window_ops.expanding import expanding_mean
from window_ops.rolling import rolling_mean


tested_models = [
    lgb.LGBMRegressor(),
    xgb.XGBRegressor(),
    RandomForestRegressor(random_state=0),
]

#rolling_mean_28: calcul moyenne glissante sur 28 jours
@njit
def rolling_mean_28(x):
    return rolling_mean(x, window_size=28)

#MlForecast: construit forecast en utilisant tout les modéles listé
fcst = MLForecast(
    models=tested_models,
    freq='D',
    lags=[7, 14, 21, 28],
    lag_transforms={
        1: [expanding_mean],
        7: [rolling_mean_28]
    },
    date_features=['dayofweek'],
    differences=[1],
)

nixtla_model = fcst.fit(generate_route_df(traffic_df,"LGW", "AMS").drop(columns = ['paired_airport']), 
          id_col = 'home_airport', time_col = 'date', target_col = 'pax_total')

predict_df = nixtla_model.predict(14)
predict_df

(pd.concat([generate_route_df(traffic_df, 'LGW', 'AMS').drop(columns=['paired_airport']),
            nixtla_model.predict(7*10)])
.set_index('date')
).plot(figsize=(15, 7));

draw_ts_multiple((pd.concat([generate_route_df(traffic_df, 'LGW', 'AMS').drop(columns=['paired_airport']),
                             nixtla_model.predict(7*10)])),
                 v1='pax_total', v2='LGBMRegressor');

crossvalidation_df = fcst.cross_validation(
    data=generate_route_df(traffic_df, "LGW", "AMS").drop(columns=['paired_airport']),
    window_size=90,
    n_windows=5,
    id_col='home_airport',
    time_col='date',
    target_col='pax_total'
)
crossvalidation_df

import numpy as np

def mse(y, y_hat):
  delta_y = np.square(y - y_hat)
  return np.nanmean(delta_y)

def rmse(y, y_hat):
  return np.sqrt(mse(y, y_hat))

cv_rmse = crossvalidation_df.groupby(['home_airport', 'cutoff']).apply(lambda df: rmse(df['pax_total'], df['LGBMRegressor'])).mean()
print("LGBM RMSE using cross-validation: ", cv_rmse)
cv_rmse = crossvalidation_df.groupby(['home_airport', 'cutoff']).apply(lambda df: rmse(df['pax_total'], df['RandomForestRegressor'])).mean()
print("RandomForest RMSE using cross-validation: ", cv_rmse)
cv_rmse = crossvalidation_df.groupby(['home_airport', 'cutoff']).apply(lambda df: rmse(df['pax_total'], df['XGBRegressor'])).mean()
print("XGBoost RMSE using cross-validation: ", cv_rmse)
#CV model par model : RF best result

cv_rmse = (crossvalidation_df
           .assign(Ensemble = lambda _df: _df[['LGBMRegressor','RandomForestRegressor', 'XGBRegressor']].mean(axis = 1))
           .groupby(['home_airport', 'cutoff']).apply(lambda df: rmse(df['pax_total'], df['Ensemble'])).mean())
print("Ensemble RMSE using cross-validation: ", cv_rmse)

"""### Model with neural forecast"""

!pip install neuralforecast

from neuralforecast import NeuralForecast
from neuralforecast.models import NBEATS, NHITS

horizon = 90
models = [NBEATS(input_size=2 * horizon, h=horizon, max_epochs=50),
          NHITS(input_size=2 * horizon, h=horizon, max_epochs=50)]
          
nforecast = NeuralForecast(models=models, freq='D')
nforecast.fit(df=generate_route_df(traffic_df, "LGW", "AMS").drop(columns=['paired_airport']).rename(columns={'home_airport': 'unique_id',
                                                                                                      'date': 'ds',
                                                                                                      'pax_total': 'y'}))

nforecast.predict().reset_index()

pd.concat(
    [
        generate_route_df(traffic_df, "LGW", "AMS").drop(columns=['paired_airport']).rename(columns={'home_airport': 'unique_id',
                                                                                                     'date': 'ds',
                                                                                                     'pax_total': 'y'}),
        nforecast.predict().reset_index()
    ]
).set_index('ds').plot(figsize=(15,7))